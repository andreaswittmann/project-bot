---
collected_at: '2025-09-26T15:59:52.649531'
collection_channel: email
company: actcon GmbH
provider_id: freelancermap
provider_name: Freelancermap
reference_id: '2923007'
scraped_date: '2025-09-26T15:59:52.650233'
source_url: https://www.freelancermap.at/nproj/2923007.html
state: rejected
state_history:
- note: 'LLM evaluation: 68% fit score'
  state: rejected
  timestamp: '2025-09-26T16:03:08.858757'
title: Senior Data Engineer (f/m/d), remote
---



# Senior Data Engineer (f/m/d), remote
**URL:** [https://www.freelancermap.at/nproj/2923007.html](https://www.freelancermap.at/nproj/2923007.html)
## Details
- **Ansprechpartner:** Paulo Dias

## Schlagworte
N/A

## Beschreibung
**Senior Data Engineer (f/m/d), remote** 
 Our client is a well-known media group based in Cologne. For the development and further development of an internal core system, we are currently looking for a Senior Data Engineer (m/f/d) 
 Start: from 01.10.2025 Duration: 2 months with extension option, fulltime Location: Mainly 100% remote, if required by arrangement for events on site in Cologne Additional requirement: No near shoring, the consultant must be based in Germany 
 **Your tasks** - Design and implementation of microservices in Python to deploy the models via a REST API, including functions to monitor these models in production
- Deployment of the microservices in the productive Google Cloud environment, taking into account high availability requirements
- Implementation of data pipelines for the preparation, provision and versioning of data for model training
- Using Terraform to build an infrastructure System
- Provision of the microservices in the productive cloud environment, taking into account high availability requirements
 
 **Your profile** - Very extensive project experience as a data engineer
- Very good experience in AWS + Terraform and Python
- Very good knowledge of microservices in a productive Google Cloud environment
- Experience in Databricks, FastAPI, Pydantic, Redis, Kubernetes are nice to have
- Very good written and spoken English, German is nice to have
- Very good communication skills and interest in helping to shape the system
 
 We look forward to receiving your application or, if applicable, your recommendation of a suitable colleague. Please send us your current profile in German or English to  Mr. Dong Chen 0221 67026756 dong.chen@jobactive.de

---

## 🤖 AI Evaluation Results

**Evaluation Timestamp:** 2025-09-26T16:03:08.855497

### Pre-Evaluation Phase
- **Score:** 19/100
- **Threshold:** 10/100
- **Result:** ✅ Passed
- **Rationale:** Score: 19%. Found tags: ['aws', 'ai', 'ki', 'ml', 'cloud', 'terraform', 'kubernetes', 'pipeline', 'python', 'api', 'rest', 'deployment', 'consultant', 'training', 'data', 'high availability', 'remote', 'freelance', 'project', 'ant']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 68/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ❌ REJECTED

#### Detailed Rationale
- Key requirements from the project offer:
  - Design and implement Python microservices to serve ML models via REST API and monitor them in production
  - Deploy microservices in Google Cloud with high availability
  - Implement data pipelines for preparation, provisioning and versioning of training data
  - Use Terraform to build infrastructure
  - Experience with Databricks, FastAPI, Pydantic, Redis, Kubernetes is a plus
  - Very good English (German nice), consultant must be based in Germany

- Strengths from the CV that match the requirements:
  - Strong Python experience and recent hands‑on AI/ML engineering: Project Bot (2025) uses Python, Flask, LangChain, multiple LLM providers and REST/API integrations — demonstrates model deployment, orchestration and production-minded engineering
  - Terraform expertise: HashiCorp Certified: Terraform Associate (2024) and practical Terraform use in private AI deployments
  - Heavy cloud and infra background: multiple AWS certifications up to Solutions Architect – Professional, many AWS projects (Landing Zone, EKS, EC2, etc.) and multi-account, high-availability architectures
  - Container and orchestration experience: Docker, Kubernetes training and KCNA (2024) plus EKS, k3s, Helm references — relevant for cloud native deployments and HA
  - Monitoring/observability exposure: lists Prometheus and Grafana as tools encountered and tested
  - Based in Germany and fluent English + native German — meets location/language requirement

- Gaps and risks vs. the offer:
  - Google Cloud specific production experience is not explicitly shown; most cloud work is AWS‑centric. The job expects very good knowledge of microservices in a productive Google Cloud environment.
  - Databricks is not mentioned in the CV — important for some data engineering stacks in GCP projects.
  - FastAPI and Pydantic are not explicitly listed; CV shows Flask for the recent project (similar but not identical to FastAPI).
  - Redis and explicit scalable data pipeline tooling (Airflow, Beam, Spark on Databricks) or large-scale data engineering projects are not prominent. The CV shows data-related tasks (data ingestion, model data preparation in Project Bot) but not large-scale ETL/Databricks experience.

- Assessment summary and recommendation:
  - Very strong match on Python, Terraform, container/Kubernetes, infrastructure, monitoring and cloud architecture skills. Recent hands-on AI/model deployment work is highly relevant.
  - Main shortfall: lack of explicit, demonstrable Google Cloud production experience and missing Databricks / FastAPI / Redis mentions. These are "nice to have" items in the brief but the role emphasises productive GCP microservices which creates some risk.
  - If the client is flexible about GCP-specific exposure (i.e., accepts strong AWS/Kubernetes/Terraform experience + ability to ramp on GCP quickly), the candidate is a very good fit. If the client requires proven, deep Databricks + GCP microservices experience from day one, this is a partial mismatch.

- Final fit score rationale (68/100):
  - +35: Excellent infrastructure, Terraform and cloud architecture credentials (AWS Pro + many AWS projects and Terraform certification)
  - +20: Strong Python and recent hands‑on ML/model deployment experience (Project Bot, LibreChat projects)
  - +8: Kubernetes, Docker and monitoring familiarity (KCNA, hands-on tooling)
  - -15: Lack of explicit Google Cloud production experience
  - -10: Missing Databricks and Redis references; FastAPI/Pydantic not shown explicitly
  - Net: 68 — recommended to propose for the role with a note about GCP ramp-up plan or brief examples of transferable GCP work (multi-cloud IaC, Terraform scripts, EKS->GKE migration capabilities) to mitigate concerns.

---
