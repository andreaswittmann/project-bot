---
company: BridgingIT GmbH
reference_id: '2915182'
scraped_date: '2025-09-03T10:00:07.605297'
source_url: https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 80% fit score'
  state: rejected
  timestamp: '2025-09-03T10:02:03.309774'
title: Supply Chain Data Engineer (ARBEITNEHMER√úBERLASSUNG!)
---


# Supply Chain Data Engineer (ARBEITNEHMER√úBERLASSUNG!)
**URL:** [https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss](https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss)
## Details
- **Start:** 09.2025
- **Von:** BridgingIT GmbH
- **Auslastung:** 100% (5 Tage pro Woche)
- **Eingestellt:** 03.09.2025
- **Ansprechpartner:** Cihan Falay
- **Projekt-ID:** 2915182
- **Branche:** Handel
- **Vertragsart:** Arbeitnehmer√ºberlassung
- **Einsatzart:** 80
                                                % Remote

## Schlagworte
Supply Chain Management, Automatisierung, Gesch√§ftsanforderungen, Python, Machine Learning, SQL, Stakeholder Management, Large Language Models, Innovation, K√ºnstliche Intelligenz, Amazon Web Services, Microsoft Azure, Unternehmensberatung, Cloud Computing, Informationssysteme, Information Engineering, Github, √úbersetzungen, Partner Relationship Management, Power Bi, Schreiben von Dokumentation, Lagerverwaltung, Tableau, Einf√ºhrung Neuer Technologien, Google Cloud, Cloud Platform, Verwaltungst√§tigkeiten, Google Data Studio, Git, Datenmanagement, Looker Analytics, Technische Beratung, Kpi-Berichterstattung

## Beschreibung
Wir, die bridgingIT-Gruppe, sind eine herstellerunabh√§ngige, produktneutrale Technologie- und Unternehmensberatung, die Kunden aus den verschiedensten Branchen bei wegweisenden Ver√§nderungsvorhaben unterst√ºtzt.

Immer dann, wenn wir aufgrund von fehlender Kapazit√§t, dennoch unseren Kunden zufrieden stellen m√∂chten, treten wir √ºber unser Partnermanagement an Externe Professionals.

Wir w√ºrden uns freuen, Sie schon bald in unserem Partnernetzwerk begr√º√üen zu d√ºrfen.

Anforderungen

‚Ä¢ Verwaltung und Pflege unserer Supply-Chain-Daten in der Cloud unter Gew√§hrleistung von Integrit√§t, Sicherheit und Zug√§nglichkeit f√ºr alle analytischen Zwecke.
‚Ä¢ Entwurf, Aufbau und Optimierung robuster Datenpipelines f√ºr die Erfassung, Transformation und das Reporting von Daten.
‚Ä¢ Entwicklung fortschrittlicher analytischer Modelle und Dashboards ‚Äì einschlie√ülich des Einsatzes von Machine Learning und Large Language Models ‚Äì zugeschnitten auf Gesch√§ftsbed√ºrfnisse und KPIs (wie Nutzung von Bestellvorschl√§gen, Prognosegenauigkeit und Lagerumschlag).
‚Ä¢ Erstellung und Pflege von Automatisierungen f√ºr Prozesse und Berichte unter Verwendung von Python und SQL.
‚Ä¢ Enge Zusammenarbeit mit Planern und Business-Stakeholdern, um Gesch√§ftsanforderungen zu verstehen, zu interpretieren und in effektive, skalierbare und benutzerfreundliche Datenl√∂sungen zu √ºbersetzen.
‚Ä¢ F√∂rderung der Einf√ºhrung neuer Technologien und analytischer Methoden, um unser Team an der Spitze der Supply-Chain-Innovation zu halten.
‚Ä¢ Technische Beratung und Unterst√ºtzung des Teams bei datenbezogenen Themen.
‚Ä¢ Dokumentation von Datenfl√ºssen, Prozessen und Best Practices.
‚Ä¢ Effektives Management und Priorisierung mehrerer Projekte und Initiativen gleichzeitig, um unter engen Zeitvorgaben hochwertige Ergebnisse zu liefern.

Muss-Kriterien:
‚Ä¢ Abgeschlossenes Bachelor- oder Masterstudium in Informatik, Data Engineering, Informationssystemen, Supply Chain oder einem verwandten Bereich.
‚Ä¢ Erfahrung in der Arbeit mit Cloud-Plattformen f√ºr Datenmanagement und Analytik (idealerweise Google Cloud Platform, aber auch AWS oder Azure werden ber√ºcksichtigt).
‚Ä¢ Erfahrung mit Git und GitHub.
‚Ä¢ Erfahrung in der Anwendung von Machine Learning oder Large Language Models im gesch√§ftlichen oder Supply-Chain-Kontext.
‚Ä¢ Erfahrung mit Daten aus der Supply Chain oder dem operativen Bereich.
‚Ä¢ Erfahrung mit Datenvisualisierungstools (z. B. Tableau, Power BI, Looker, Google Data Studio).
‚Ä¢ Erfahrung in der Integration von generativen KI-Modellen.
‚Ä¢ Exzellente Kenntnisse in SQL und Python sowie praktische Erfahrung im Aufbau von Datenpipelines, Modellen und Automatisierungen.
‚Ä¢ Nachweisliche F√§higkeit, Gesch√§ftsanforderungen schnell und pr√§zise zu interpretieren und L√∂sungen zu liefern, die f√ºr Business-Anwender direkt umsetzbar und wertvoll sind.
‚Ä¢ Nachgewiesene F√§higkeit, Datenl√∂sungen und Insights in einer Geschwindigkeit und Qualit√§t zu liefern, die Sie von anderen abhebt ‚Äì idealerweise sind Sie jemand, der Ergebnisse f√ºnfmal schneller und besser erzielt als Ihre Kollegen.
‚Ä¢ F√§higkeit, mehrere Projekte und Initiativen gleichzeitig zu managen und hervorragende Ergebnisse trotz wechselnder Priorit√§ten zu gew√§hrleisten.
‚Ä¢ Starke Kommunikationsf√§higkeiten und die F√§higkeit, effektiv mit nicht-technischen Stakeholdern zusammenzuarbeiten.
‚Ä¢ Flie√üende Englischkenntnisse.

Melden Sie sich bei Interesse oder R√ºckfragen jederzeit gerne bei Ihrem Ansprechpartner:

Cihan Falay

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T10:02:03.305901

### Pre-Evaluation Phase
- **Score:** 18/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 18%. Found tags: ['aws', 'amazon', 'ai', 'ki', 'generative', 'machine learning', 'cloud', 'pipeline', 'python', 'git', 'github', 'sql', 'integration', 'beratung', 'data', 'analytics', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 80/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements (short):
  - Bachelor/Master in CS/Data Engineering/related
  - Cloud data platform experience (GCP preferred, AWS/Azure acceptable)
  - Strong SQL and Python; build data pipelines and automations
  - Experience with ML / Large Language Models and integration of generative AI
  - Supply-chain / operational data experience
  - Git/GitHub, CI/CD and Infrastructure-as-Code
  - Data-visualization tools (Tableau, Power BI, Looker, Google Data Studio)
  - Stakeholder communication, ability to manage multiple projects; fluent English

- Match vs CV (concise):
  - Education: Diplom-Informatiker (equivalent) ‚Üí ‚úÖ
  - Cloud: extensive AWS experience and many AWS data/AI services; Terraform, Kubernetes, Docker ‚Üí ‚úÖ (strong AWS, no explicit GCP examples)
  - SQL & Python: extensive Oracle/DB and Python/bash usage across projects ‚Üí ‚úÖ
  - Data pipelines / automation: experience with CI/CD (GitLab CI/CD, Jenkins), Infrastructure as Code (Terraform, SaltStack, CloudFormation) and automated deployments ‚Üí ‚úÖ
  - ML / LLMs: recent projects (2024/2025) integrating LibreChat, AWS Bedrock, Ollama, RAG and AWS AI Practitioner cert ‚Üí ‚úÖ
  - Supply-chain domain: many engagements for logistics/post/transport clients (infrastructure, middleware, migrations) but few explicit examples of supply-chain analytics, forecasting or inventory-model development ‚Üí partial
  - Git/GitHub: stated and used (Git, GitHub, GitLab) ‚Üí ‚úÖ
  - Data visualization: Prometheus/Grafana basic experience mentioned; no explicit Tableau/Power BI/Looker/Google Data Studio experience in CV ‚Üí gap
  - Stakeholder & consulting skills: long consulting background, architecture & client-facing roles, fluent English ‚Üí ‚úÖ

- Gaps / Risks to validate in interview:
  - Direct, demonstrable experience building supply-chain analytical models (forecasting, inventory KPIs) and working with operational supply-chain datasets ‚Äî CV shows domain exposure but mostly infra/ESB/WebLogic work.
  - Hands-on experience with GCP and with BI tools like Tableau/Power BI/Looker/Google Data Studio is not shown.
  - Specific modern data engineering stack items (Airflow, dbt, Spark, BigQuery) are not documented.

- Scoring rationale (summary of weighting):
  - Degree and consulting/communication: +10
  - Strong AWS/cloud + IaC/DevOps + CI/CD (core for pipelines & reliability): +20
  - Python & SQL experience: +15
  - Recent ML/LLM & generative AI integration experience + certifications: +15
  - Domain exposure to logistics/supply-chain clients (infrastructure side): +8
  - Missing explicit BI/visualization tooling and missing GCP and modern data-engineering tools: -18
  - Overall conservatism for unknown hands‚Äëon supply-chain analytics depth: -5

- Recommendation: Good-to-very-good technical and architectural fit (especially for a cloud/LLM-enabled data engineering role). Proceed to interview to validate hands‚Äëon supply‚Äëchain analytics, BI-tool experience and GCP familiarity; candidate likely to ramp quickly on missing tooling given strong cloud/DevOps/AI background.

---


---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T10:02:48.883143

### Pre-Evaluation Phase
- **Score:** 43/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 43%. Found tags: ['aws', 'amazon', 'bedrock', 'ai', 'ki', 'llm', 'openai', 'generative', 'machine learning', 'ml', 'cloud', 'terraform', 'kubernetes', 'docker', 'prometheus', 'grafana', 'architect', 'architecture', 'devops', 'ci/cd', 'pipeline', 'jenkins', 'gitlab', 'automation', 'infrastructure as code', 'iac', 'saltstack', 'python', 'bash', 'git', 'github', 'oracle', 'weblogic', 'sql', 'middleware', 'integration', 'esb', 'deployment', 'beratung', 'consulting', 'data', 'analytics', 'remote', 'freelance', 'projekt', 'project']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 82/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key project requirements:
  - Abschluss in Informatik / Data Engineering (Bachelor/Master)
  - Cloud-data-platform experience (GCP preferred; AWS/Azure acceptable)
  - Strong Python & SQL, experience building data pipelines/automation
  - ML / LLM and integration of generative AI into business workflows
  - Experience with supply‚Äëchain / operational data and relevant KPIs
  - Git/GitHub, CI/CD, IaC; data-visualization tools (Tableau, Power BI, Looker, GDS)
  - Stakeholder communication, multi-project management, fluent English

- Match vs CV (concise):
  - Education: Diplom-Informatiker (equivalent) ‚Üí ‚úÖ
  - Cloud: Extensive AWS (Solutions Architect Pro, many AWS services), Terraform, Kubernetes, Docker ‚Üí ‚úÖ (strong AWS; no explicit GCP)
  - Python & SQL: multiple projects with Python, Oracle/DB experience ‚Üí ‚úÖ
  - Data pipelines / automation: CI/CD (GitLab CI/CD, Jenkins), IaC (Terraform, CloudFormation, SaltStack) ‚Üí ‚úÖ
  - ML / LLM: recent hands‚Äëon LibreChat, AWS Bedrock, RAG, Ollama, AWS AI Practitioner ‚Üí ‚úÖ
  - Supply‚Äëchain domain: strong exposure to logistics / post / transport clients (infra & migration work) but limited evidence of hands‚Äëon supply‚Äëchain analytics (forecasting, inventory models) ‚Üí partial
  - Git/GitHub: used and documented ‚Üí ‚úÖ
  - BI / visualization: only Prometheus/Grafana basic experience; no explicit Tableau/Power BI/Looker/Google Data Studio examples ‚Üí gap
  - GCP & modern data stack (BigQuery, Airflow, dbt, Spark): not shown ‚Üí gap
  - Consulting, stakeholder communication, English: extensive consulting history and fluent English ‚Üí ‚úÖ

- Risks / gaps to validate in interview:
  - Direct experience building supply‚Äëchain analytical models (demand forecasting, inventory optimization) and working with operational supply‚Äëchain datasets
  - Hands‚Äëon experience with GCP and common data‚Äëengineering tools (Airflow, dbt, BigQuery, Spark)
  - Experience with mainstream BI tools (Tableau, Power BI, Looker, Google Data Studio)
  - Employment/engagement model: role is Arbeitnehmer√ºberlassung (employee‚Äëstyle); candidate is a GmbH owner ‚Äî confirm willingness/eligibility for temp employment

- Overall assessment / scoring rationale (concise):
  - Strong positives: degree, very strong AWS/cloud + IaC, solid Python/SQL, CI/CD experience, recent practical LLM/AI projects and certifications, domain exposure to logistics clients, senior consulting/communication skills.  (+)
  - Deductions: no explicit GCP experience, no documented BI tool experience, limited explicit evidence of supply‚Äëchain analytics/modeling and modern data‚Äëengineering tools. (-)

Conclusion: Good to very good technical and architectural fit (particularly for an AWS/LLM enabled data‚Äëengineering role). Score 82/100 ‚Äî recommend interview to validate hands‚Äëon supply‚Äëchain analytics, BI tooling, GCP familiarity and employment model acceptance.

---
