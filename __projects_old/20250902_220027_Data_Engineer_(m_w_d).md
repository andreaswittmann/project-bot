---
company: Hays AG
reference_id: '2915127'
scraped_date: '2025-09-02T22:00:27.597714'
source_url: https://www.freelancermap.at/projekt/data-engineer-m-w-d-2915127?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 60% fit score'
  state: rejected
  timestamp: '2025-09-02T22:03:15.717765'
title: Data Engineer (m/w/d)
---


# Data Engineer (m/w/d)
**URL:** [https://www.freelancermap.at/projekt/data-engineer-m-w-d-2915127?ref=rss](https://www.freelancermap.at/projekt/data-engineer-m-w-d-2915127?ref=rss)
## Details
- **Start:** ab sofort
- **Von:** Hays AG
- **Eingestellt:** 02.09.2025
- **Ansprechpartner:** Hays AG
- **Projekt-ID:** 2915127
- **Branche:** IT
- **Vertragsart:** Freiberuflich

## Schlagworte
Databricks, Pyspark, Python, Streaming, Apache Spark, Architektur, Partnerschaften, Continuous Integration, Vertragsverhandlung, Digitalisierung, Rekrutierung, Skalierbarkeit, Objektorientierte Software-Entwicklung, Performance-Tuning, Software Architecture, Verwaltungst√§tigkeiten, Refactoring

## Beschreibung
**Data Engineer (m/w/d)**

Referenz: -de
Beginn: asap
Dauer: 6 MM++

**Meine Aufgaben:**

- Entwicklung und Weiterentwicklung einer Streaming-Pipeline mit Databricks DLT unter Verwendung von PySpark
- Optimierung von PySpark-Code zur effizienten Verarbeitung von Streaming-Daten
- Pflege und Deployment eines Databricks Asset Bundles (DAB) zur strukturierten Verwaltung von Projektartefakten
- Weiterentwicklung und Implementierung objektorientierter Python-Komponenten, insbesondere im Kontext von Apache Spark
- Performance-Tuning und Code-Refactoring zur Sicherstellung von Skalierbarkeit und Wartbarkeit

**Meine Qualifikation:**

- Fundierte Erfahrung in der Entwicklung mit PySpark und Apache Spark
- Tiefes Verst√§ndnis von Streaming-Architekturen und deren Herausforderungen
- Erfahrung mit Databricks DLT und DAB
- Sicherer Umgang mit objektorientierter Programmierung in Python
- Kenntnisse in Deployment-Prozessen innerhalb von Databricks-Umgebungen
- TechStack: Databricks, Apache Spark, PySpark, Python, CI/CD f√ºr Databricks Deployment

**Meine Vorteile:**

- Internationaler Kunde
- Remote-M√∂glichkeit

**√úber uns:**
Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot ‚Äì egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung ‚Äì dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat ‚Äì v√∂llig kostenfrei, diskret und unverbindlich! Wir freuen uns auf Sie.

**Mein Kontakt bei Hays:**

Mein Ansprechpartner:
Vincent Ru√ü

Referenznummer:

Kontakt aufnehmen:
Email:

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-02T22:03:15.697327

### Pre-Evaluation Phase
- **Score:** 19/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 19%. Found tags: ['ai', 'architect', 'architekt', 'architecture', 'architektur', 'ci/cd', 'pipeline', 'python', 'git', 'rest', 'integration', 'agile', 'continuous', 'deployment', 'beratung', 'data', 'streaming', 'skalierbarkeit', 'performance', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **Fit Score:** 60/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- **PySpark and Apache Spark:** The project offer requires experience with PySpark and Apache Spark, whereas Andreas's CV does not explicitly mention these technologies, suggesting a gap in this area.
- **Streaming Architectures:** The project requires a deep understanding of streaming architectures. Although Andreas has experience with various cloud and enterprise solutions, specific experience with streaming pipelines like the ones required is not detailed in his CV.
- **Databricks DLT and DAB:** The offer specifies knowledge of Databricks DLT and DAB. The CV mentions a broad knowledge of AWS and cloud technologies but no specific experience with Databricks.
- **Object-Oriented Python Programming:** While Andreas has extensive experience in software development, particularly Java and enterprise systems, his CV does not highlight expertise specifically in Python or object-oriented Python programming, which is crucial for this role.
- **CI/CD Knowledge for Databricks Deployment:** Andreas has a strong background in CI/CD and DevOps methodologies for a variety of environments, but the CV does not indicate specific experience with Databricks environments.
- **TechStack (Databricks, Apache Spark, PySpark, Python, CI/CD):** While Andreas demonstrates expertise in enterprise IT solutions with a focus on AWS, Terraform, Kubernetes, and more, the specific tech stack for this offer is not prominently covered in his experience.
- **Remote Work and International Experience:** As an entrepreneur and consultant, Andreas likely has a flexible approach to remote work and possibly international exposure, though this is not explicitly detailed.
- **General Software Architecture and Performance Tuning:** Andreas has extensive experience in software architecture and performance tuning, aligning well with these high-level requirements of the job offer.

---
