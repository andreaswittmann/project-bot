---
company: Randstad Digital Germany AG
reference_id: '2916176'
scraped_date: '2025-09-05T13:00:05.916944'
source_url: https://www.freelancermap.de/projekt/data-engineer-m-w-d-python-2916176?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 54% fit score'
  state: rejected
  timestamp: '2025-09-05T13:00:39.359277'
title: Data Engineer (m/w/d) Python
---


# Data Engineer (m/w/d) Python
**URL:** [https://www.freelancermap.de/projekt/data-engineer-m-w-d-python-2916176?ref=rss](https://www.freelancermap.de/projekt/data-engineer-m-w-d-python-2916176?ref=rss)
## Details
- **Start:** 10.2025
- **Von:** Randstad Digital Germany AG
- **Auslastung:** 100% (5 Tage pro Woche)
- **Eingestellt:** 05.09.2025
- **Ansprechpartner:** Jeannine Keith
- **Projekt-ID:** 2916176
- **Branche:** Verkehr und Logistik
- **Vertragsart:** Freiberuflich
- **Einsatzart:** 80
                                                % Remote

## Schlagworte
Python, Amazon Web Services, Big Data, Gesch√§ftsanforderungen, Cloud Computing, Datenvalidierung, Datenmodell, Datenqualit√§t, Relationale Datenbanken, Apache Hadoop, Redis, Umstrukturierung, Streaming, Verwaltungst√§tigkeiten, Datenstrategie, Kubernetes, Apache Flink, Logistikprozesse

## Beschreibung
F√ºr unseren Kunden suche ich Data Engineer (m/w/d) Python f√ºr ein remote Projekt& Frankfurt.

Aufgaben:
‚Ä¢ Technische Weiterentwicklung unserer Datenpipelines (Batch und Streaming) in der AWS Cloud im Python Code
‚Ä¢ Sicherstellung Datenqualit√§t und Entwurf relationale und nicht-relationale Datenmodelle zur Er-f√ºllung der Gesch√§ftsanforderungen
‚Ä¢ Entwicklung und Betrieb von internen und externen Schnittstellen zur Bereitstellung von Daten-produkten
‚Ä¢ Weiterentwicklung unserer Datenstrategie
‚Ä¢ Beratung der Projektmitglieder zum Einsatz unterschiedlicher AWS Technologien und Datenquali-t√§tssicherung
‚Ä¢ Entwicklung datengetriebener Softwarekomponenten zur Optimierung von Dispositionsentschei-dungen und verantwortet ein m√∂glichst reibungsloses, effizientes und fehlerfreies Bereitstellen der Datenquellen und deren Aggregationen

Anforderungen must have, sind zwingend erforderlich auch in Jahren und m√ºssen in den Projekten aufgef√ºhrt sein!
‚Ä¢ Umfangreiche und aktuelle Kenntnisse mit dem Aufbau und der Restrukturierung von Datenarchitekturen insbesondere relationale und nicht relationale Datenbanken; Berufserfahrung in mindestens 3 Kundenprojekten
‚Ä¢ Praktische Erfahrungen mit Big Data Tools wie z.B. Redis, Flink, Hadoop; In mind. 3 Projekten
‚Ä¢ Praktische Erfahrung mit Frameworks zur Datenvalidierung wie z.B. Great Expectation, Pandera oder TFDV hinzuf√ºgen; Mind. 3 Jahres Berufserfahrung
‚Ä¢ Erfahrung in der Verwaltung von Kubernetes Clustern; In mind. 3 Projekten
‚Ä¢ Umfangreiche Erfahrung in der Python Programmierung; Mind. 10 Jahre Berufserfahrung

Anforderungen nice to have:
‚Ä¢ Erfahrungen in anderen Gro√ükonzernen; Projekte in mind. einem weiteren Konzern
‚Ä¢ Erfahrung innerhalb des Sektors Transport und Logistik; Nachweisliche Erfahrung von mindestens einem Datenprojekt innerhalb des Sektors
‚Ä¢ Erfahrung mit Great Expectations; Nachweis der Qualifikation √ºber Projekterfahrung
‚Ä¢ Erfahrung mit Lambda; Nachweis der Qualifikation √ºber Projekterfahrung
‚Ä¢ Erfahrung mit CDK; Nachweis der Qualifikation √ºber Projekterfahrung

Zeitraum - von: vsl.20.09.2025
Zeitraum - bis: 31.12.2025
Profile bis: 08.09.2025 um 9Uhr
Tagessatz allin: 550 ‚Ç¨, 70 PT remote, 7 Frankfurt
Projektsprache: deutsch
Ich freue mich auf die Zusendung Ihres Profils, inkl. Verf√ºgbarkeit

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-05T13:00:39.356869

### Pre-Evaluation Phase
- **Score:** 18/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 18%. Found tags: ['aws', 'amazon', 'ai', 'cloud', 'kubernetes', 'architekt', 'architektur', 'pipeline', 'python', 'git', 'rest', 'beratung', 'data', 'big data', 'streaming', 'remote', 'freelance', 'projekt', 'ant']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 54/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key project requirements (summary):
  - Extensive Python programming (>=10 years)
  - Design/restructuring of data architectures (relational + non-relational) in >=3 client projects
  - Practical experience with Big Data tools (Redis, Flink, Hadoop) in >=3 projects
  - Experience with data validation frameworks (Great Expectations, Pandera, TFDV) ‚Äî >=3 years
  - Management of Kubernetes clusters in >=3 projects
  - Nice-to-have: experience in large corporates and transport/logistics, Great Expectations, Lambda, CDK

- Match vs CV (evidence):
  - Python: Strong. Multiple projects list Python across many years (migration, automation, integration, CI/CD). Clearly >10 years -> ‚úîÔ∏è
  - Data architecture (relational + non-relational): Partial/Good. Extensive relational DB (Oracle, RDS) experience and AWS data architecture work (SAP BW/4HANA on AWS, Landing Zone, many AWS services). Non-relational evidence is mostly implicit (AWS services list includes DynamoDB/DocumentDB/OpenSearch) but not clearly shown as hands-on in 3 client projects -> ‚ö†Ô∏è
  - Big Data tools (Redis, Flink, Hadoop): Weak/No evidence. CV does not demonstrate hands‚Äëon Redis, Flink or Hadoop in customer projects (ElasticSearch/OpenSearch and Kafka/MSK-like messaging occur, but required tools not shown) -> ‚ùå
  - Data validation frameworks (Great Expectations, Pandera, TFDV): No evidence. No projects reference these tools or equivalent data-quality frameworks -> ‚ùå
  - Kubernetes cluster management: Partial. Has KCNA certification (2024) and lists Kubernetes/EKS in training/technology stacks; concrete evidence of operating/managing K8s clusters across 3 client projects is not clearly documented -> ‚ö†Ô∏è
  - Sector / corporate experience: Strong. Multiple projects for international logistics/transport clients and large enterprises -> ‚úîÔ∏è
  - AWS, Terraform, CI/CD, IaC, observability, DevOps: Strong. Many projects and recent professional certs (AWS Pro, Terraform Associate, GitHub Copilot, KCNA) -> ‚úîÔ∏è

- Concise assessment / impact on fit:
  - Strengths that match the role: very strong Python, deep AWS/architecture and enterprise project experience, clear domain experience in transport/logistics, IaC and DevOps background.
  - Critical gaps vs mandatory requirements: explicit project experience with Redis/Flink/Hadoop and use of data-validation frameworks (Great Expectations/Pandera/TFDV) is missing. Kubernetes experience is proven by certification/training but not clearly by 3+ customer projects.
  - These missing items are explicit must-haves in the brief; absence lowers the overall compliance even though the candidate could likely learn/adapt quickly given broad cloud/DevOps background.

- Recommendation: Candidate is a strong senior cloud/data-architecture hire with excellent Python and AWS skills and relevant logistics experience, but does not convincingly meet several of the project's strict must-have requirements (Big Data toolset & data-validation frameworks + documented multi-project K8s operations). If the client can relax the strict tool-specific requirements or accepts fast ramp-up/trial, this candidate is worth proposing; otherwise he is a partial fit.

- Fit-score rationale (numeric): 54/100 ‚Äî full points for Python and enterprise/AWS architecture strengths, partial for Kubernetes and data-architecture, zero for missing explicit Big Data tool and data-validation framework experience.

---
