---
company: BridgingIT GmbH
reference_id: '2915182'
scraped_date: '2025-09-03T10:00:08.011601'
source_url: https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss
state: sent
state_history:
- note: 'LLM evaluation: 80% fit score'
  state: rejected
  timestamp: '2025-09-03T10:01:11.531006'
- note: 'LLM evaluation: 85% fit score'
  state: accepted
  timestamp: '2025-09-03T10:01:31.484330'
- note: Starting application generation
  state: applied
  timestamp: '2025-09-03T10:02:45.503017'
- note: Sent from editor
  state: sent
  timestamp: '2025-09-03T10:11:16.607006'
title: Supply Chain Data Engineer (ARBEITNEHMER√úBERLASSUNG!)
---





# Supply Chain Data Engineer (ARBEITNEHMER√úBERLASSUNG!)
**URL:** [https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss](https://www.freelancermap.de/projekt/supply-chain-data-engineer-arbeitnehmerueberlassung?ref=rss)
## Details
- **Start:** 09.2025
- **Von:** BridgingIT GmbH
- **Auslastung:** 100% (5 Tage pro Woche)
- **Eingestellt:** 03.09.2025
- **Ansprechpartner:** Cihan Falay
- **Projekt-ID:** 2915182
- **Branche:** Handel
- **Vertragsart:** Arbeitnehmer√ºberlassung
- **Einsatzart:** 80
                                                % Remote

## Schlagworte
Supply Chain Management, Automatisierung, Gesch√§ftsanforderungen, Python, Machine Learning, SQL, Stakeholder Management, Large Language Models, Innovation, K√ºnstliche Intelligenz, Amazon Web Services, Microsoft Azure, Unternehmensberatung, Cloud Computing, Informationssysteme, Information Engineering, Github, √úbersetzungen, Partner Relationship Management, Power Bi, Schreiben von Dokumentation, Lagerverwaltung, Tableau, Einf√ºhrung Neuer Technologien, Google Cloud, Cloud Platform, Verwaltungst√§tigkeiten, Google Data Studio, Git, Datenmanagement, Looker Analytics, Technische Beratung, Kpi-Berichterstattung

## Beschreibung
Wir, die bridgingIT-Gruppe, sind eine herstellerunabh√§ngige, produktneutrale Technologie- und Unternehmensberatung, die Kunden aus den verschiedensten Branchen bei wegweisenden Ver√§nderungsvorhaben unterst√ºtzt.

Immer dann, wenn wir aufgrund von fehlender Kapazit√§t, dennoch unseren Kunden zufrieden stellen m√∂chten, treten wir √ºber unser Partnermanagement an Externe Professionals.

Wir w√ºrden uns freuen, Sie schon bald in unserem Partnernetzwerk begr√º√üen zu d√ºrfen.

Anforderungen

‚Ä¢ Verwaltung und Pflege unserer Supply-Chain-Daten in der Cloud unter Gew√§hrleistung von Integrit√§t, Sicherheit und Zug√§nglichkeit f√ºr alle analytischen Zwecke.
‚Ä¢ Entwurf, Aufbau und Optimierung robuster Datenpipelines f√ºr die Erfassung, Transformation und das Reporting von Daten.
‚Ä¢ Entwicklung fortschrittlicher analytischer Modelle und Dashboards ‚Äì einschlie√ülich des Einsatzes von Machine Learning und Large Language Models ‚Äì zugeschnitten auf Gesch√§ftsbed√ºrfnisse und KPIs (wie Nutzung von Bestellvorschl√§gen, Prognosegenauigkeit und Lagerumschlag).
‚Ä¢ Erstellung und Pflege von Automatisierungen f√ºr Prozesse und Berichte unter Verwendung von Python und SQL.
‚Ä¢ Enge Zusammenarbeit mit Planern und Business-Stakeholdern, um Gesch√§ftsanforderungen zu verstehen, zu interpretieren und in effektive, skalierbare und benutzerfreundliche Datenl√∂sungen zu √ºbersetzen.
‚Ä¢ F√∂rderung der Einf√ºhrung neuer Technologien und analytischer Methoden, um unser Team an der Spitze der Supply-Chain-Innovation zu halten.
‚Ä¢ Technische Beratung und Unterst√ºtzung des Teams bei datenbezogenen Themen.
‚Ä¢ Dokumentation von Datenfl√ºssen, Prozessen und Best Practices.
‚Ä¢ Effektives Management und Priorisierung mehrerer Projekte und Initiativen gleichzeitig, um unter engen Zeitvorgaben hochwertige Ergebnisse zu liefern.

Muss-Kriterien:
‚Ä¢ Abgeschlossenes Bachelor- oder Masterstudium in Informatik, Data Engineering, Informationssystemen, Supply Chain oder einem verwandten Bereich.
‚Ä¢ Erfahrung in der Arbeit mit Cloud-Plattformen f√ºr Datenmanagement und Analytik (idealerweise Google Cloud Platform, aber auch AWS oder Azure werden ber√ºcksichtigt).
‚Ä¢ Erfahrung mit Git und GitHub.
‚Ä¢ Erfahrung in der Anwendung von Machine Learning oder Large Language Models im gesch√§ftlichen oder Supply-Chain-Kontext.
‚Ä¢ Erfahrung mit Daten aus der Supply Chain oder dem operativen Bereich.
‚Ä¢ Erfahrung mit Datenvisualisierungstools (z. B. Tableau, Power BI, Looker, Google Data Studio).
‚Ä¢ Erfahrung in der Integration von generativen KI-Modellen.
‚Ä¢ Exzellente Kenntnisse in SQL und Python sowie praktische Erfahrung im Aufbau von Datenpipelines, Modellen und Automatisierungen.
‚Ä¢ Nachweisliche F√§higkeit, Gesch√§ftsanforderungen schnell und pr√§zise zu interpretieren und L√∂sungen zu liefern, die f√ºr Business-Anwender direkt umsetzbar und wertvoll sind.
‚Ä¢ Nachgewiesene F√§higkeit, Datenl√∂sungen und Insights in einer Geschwindigkeit und Qualit√§t zu liefern, die Sie von anderen abhebt ‚Äì idealerweise sind Sie jemand, der Ergebnisse f√ºnfmal schneller und besser erzielt als Ihre Kollegen.
‚Ä¢ F√§higkeit, mehrere Projekte und Initiativen gleichzeitig zu managen und hervorragende Ergebnisse trotz wechselnder Priorit√§ten zu gew√§hrleisten.
‚Ä¢ Starke Kommunikationsf√§higkeiten und die F√§higkeit, effektiv mit nicht-technischen Stakeholdern zusammenzuarbeiten.
‚Ä¢ Flie√üende Englischkenntnisse.

Melden Sie sich bei Interesse oder R√ºckfragen jederzeit gerne bei Ihrem Ansprechpartner:

Cihan Falay

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T10:01:11.526957

### Pre-Evaluation Phase
- **Score:** 18/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 18%. Found tags: ['aws', 'amazon', 'ai', 'ki', 'generative', 'machine learning', 'cloud', 'pipeline', 'python', 'git', 'github', 'sql', 'integration', 'beratung', 'data', 'analytics', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 80/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements (summary): Bachelor/Master in CS or related; cloud data platform experience (GCP preferred, AWS/Azure acceptable); Git/GitHub; SQL & Python; building/operationalizing data pipelines; ML / LLM experience and integration of generative AI; supply-chain / operational data experience; data-visualization (Tableau/Power BI/Looker/QuickSight); stakeholder communication and consulting; ability to manage multiple projects; fluent English.

- Matches / strengths:
  - Degree: Diplom-Informatiker (equivalent to Master) ‚Äî ‚úÖ
  - Cloud: Extensive, deep AWS experience and multiple AWS certs (Solutions Architect Pro, SysOps, Developer, AI Practitioner); Terraform, EKS/Kubernetes, Docker ‚Äî strong fit for cloud-based data management on AWS (GCP not shown) ‚Äî ‚úÖ (AWS), ‚ö†Ô∏è (GCP missing)
  - Git/GitHub: documented Git, GitHub usage and GitHub Copilot certification ‚Äî ‚úÖ
  - Python & SQL: multiple projects list Python + Oracle/SQL DB work; strong scripting and automation experience ‚Äî ‚úÖ
  - Data pipelines / automation: experienced in Infrastructure-as-Code (Terraform, CloudFormation), CI/CD (GitLab CI, Jenkins), automated provisioning and migrations; built reproducible cloud deployments ‚Äî good infra/data-pipeline foundation ‚Äî ‚úÖ (infrastructure side)
  - ML / LLM & generative AI: recent projects with LibreChat, AWS Bedrock, Ollama, RAG, prompt engineering; AWS SageMaker awareness via training ‚Äî solid hands-on/architect experience integrating LLMs ‚Äî ‚úÖ
  - Supply-chain / operational domain exposure: multiple long-term clients in logistics/transport and a SAP BW/4HANA on AWS design for a machine-builder ‚Äî domain knowledge present though often on middleware/infra side rather than analytics model development ‚Äî ‚ö†Ô∏è (domain exposure present, limited explicit analytics use-cases)
  - Data viz: AWS QuickSight listed in trainings; not explicit Power BI/Tableau/Looker hands-on examples but transferable skills likely ‚Äî ‚ö†Ô∏è (partial)
  - Communication / stakeholder management: decades as consultant/architect and founder; demonstrated client-facing experience ‚Äî ‚úÖ
  - Project multitasking / delivery speed: extensive consulting history, CI/CD / automation focus supports rapid delivery claims ‚Äî ‚úÖ
  - Language: Fluent English documented ‚Äî ‚úÖ

- Gaps / risks:
  - No explicit evidence of GCP (BigQuery, Dataflow) or core GCP data tooling ‚Äî client prefers GCP but accepts AWS/Azure.
  - Limited explicit evidence of modern data engineering tools often used in analytics teams (Airflow, dbt, Spark) in hands-on context; training lists many AWS data services but fewer proof points of building ML forecasting models or supply-chain KPI models end-to-end.
  - Data visualization tools such as Tableau / Power BI / Looker not strongly evidenced (QuickSight present in AWS list).
  - The CV emphasizes platform/middleware/DevOps/architecture; role expects operational analytics & ML model development focused on supply-chain KPIs ‚Äî some translation of skills required.

- Overall assessment: Very strong cloud-infrastructure, automation, LLM/genAI and consulting background; meets core technical must-haves (AWS, Git, Python, SQL, LLM integration) and has supply-chain domain exposure via logistics clients and SAP BW work. Missing explicit GCP and less explicit hands-on history with analytics-first pipelines / BI-stack (Tableau/PowerBI/dbt/Airflow/Spark), but these are likely bridgeable given the candidate's infrastructure, ML/LLM and automation experience.

- Recommendation: High-probability candidate for the role if the client accepts AWS-first profiles and values strong DevOps/ML-integration + logistics domain knowledge; consider technical interview to verify hands-on experience building end-to-end supply-chain forecasting models, data pipeline orchestration (Airflow/dbt) and BI/dashboard examples.

---


---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T10:01:31.480065

### Pre-Evaluation Phase
- **Score:** 18/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 18%. Found tags: ['aws', 'amazon', 'ai', 'ki', 'generative', 'machine learning', 'cloud', 'pipeline', 'python', 'git', 'github', 'sql', 'integration', 'beratung', 'data', 'analytics', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 85/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚úÖ ACCEPTED

#### Detailed Rationale
- Key project requirements:
  - Cloud data platform experience (GCP ideal; AWS/Azure accepted)
  - Design/build/optimize data pipelines; strong Python & SQL skills
  - Machine Learning and Large Language Model (LLM) experience and integration (RAG, generative AI)
  - Experience with supply-chain / operational data and KPIs
  - BI / dashboarding tools (Tableau, Power BI, Looker, Google Data Studio)
  - Git/GitHub, automation, documentation, stakeholder management, ability to deliver fast

- Strong matches from CV:
  - Degree: Diplom‚ÄëInformatiker (meets academic requirement).
  - Cloud: extensive AWS certifications (Associate -> Professional) and many AWS services listed and used; Terraform, Kubernetes (KCNA), Docker ‚Äî strong cloud & infra pedigree.
  - Python & SQL: repeated hands‚Äëon use (Python, Bash, Oracle SQL, many DB migrations) and proven experience building automated processes and CI/CD pipelines.
  - Git/GitHub and CI/CD: Git, GitLab CI/CD, GitHub Copilot certification and practical repo/workflow experience.
  - ML / LLMs: recent projects (2025) building private AI knowledge environment with LibreChat, AWS Bedrock, Ollama, RAG; AWS Certified AI Practitioner ‚Äî clear generative AI / LLM integration experience.
  - Supply chain domain: multiple projects for logistics/transport/post clients ‚Äî domain familiarity with operational data.
  - Automation, documentation, stakeholder work: long consulting background with architecture, migration, stakeholder engagement, live-scripting documentation approach.

- Partial / weaker matches / risks:
  - GCP: no explicit GCP production experience shown (CV focuses heavily on AWS). The role prefers GCP but states AWS/Azure acceptable.
  - BI tools: explicit hands‚Äëon experience with Tableau / Power BI / Looker / Google Data Studio is not shown; AWS QuickSight is listed in training material, and Prometheus/Grafana knowledge is basic. Might need upskilling or quick ramp for specific BI tooling.
  - Pure Data Engineering evidence: while automation, ETL/migration and infra-as-code experience are strong, there are fewer explicit examples of large-scale data warehouse builds (e.g., BigQuery, Redshift, Glue jobs in production) beyond training lists. However, relevant skills are transferable.
  - Quantified ML in supply‚Äëchain: certifications and LLM project exist, but fewer delivered examples of classic ML forecasting models (demand forecasting, inventory optimization) in production for supply chain KPIs (though SAP BW/4HANA and analytics work shows analytical architecture capability).

- Overall assessment & recommendation:
  - Andreas is a strong fit (senior, architect-level) for the role due to deep AWS/cloud, automation, Python/SQL, Git, LLM/integration and supply‚Äëchain consulting experience. He may need to clarify/confirm recent hands‚Äëon work with the specific BI stack (Tableau/Power BI/Looker) and GCP if the client strictly prefers GCP-native implementations. For a BridgingIT engagement that accepts AWS-first candidates and values rapid delivery and architecture/consulting skills, Andreas should be presented as a high-probability match.

- Suggested messaging when submitting CV:
  - Emphasize recent 2025 LLM/LibreChat + AWS Bedrock project and Terraform-based automated deployments.
  - Highlight logistics/supply-chain clients and SAP on AWS experience.
  - Note readiness to adopt specific BI tools quickly and ability to translate business KPIs into data solutions.

---

## Generated Application
**Generation Date**: 2025-09-03 10:03:18  
**AI Provider**: ANTHROPIC  
**Model**: claude-sonnet-4-20250514  
**Tokens Used**: 696.8000000000001  
**Estimated Cost**: $0.0038  

MARKER_APPLICATION_START
Position: Supply Chain Data Engineer
Referenznummer: 2915182

Sehr geehrte Damen und Herren,

hiermit bewerbe ich mich f√ºr die ausgeschriebene Position als Supply Chain Data Engineer bei der BridgingIT GmbH. Mit fast 30 Jahren IT-Erfahrung bringe ich fundierte Expertise in Cloud-Architekturen, Datenmanagement und modernen KI-Technologien mit. Meine aktuellen Zertifizierungen umfassen AWS Certified Solutions Architect Professional, AWS Certified AI Practitioner, HashiCorp Certified Terraform Associate, Kubernetes and Cloud Native Associate (KCNA) sowie GitHub Copilot Certification.

**Abgeschlossenes Studium in relevanten Bereichen:**
Ich verf√ºge √ºber einen Abschluss als Diplom-Informatiker mit der Note "Sehr Gut" (1994: Technische Universit√§t Berlin), was einem Master-Abschluss entspricht und die Anforderung vollst√§ndig erf√ºllt.

**Cloud-Plattformen f√ºr Datenmanagement und Analytik:**
Meine Expertise liegt prim√§r in Amazon Web Services mit umfassenden Zertifizierungen und praktischer Erfahrung (2024: AWS Certified Solutions Architect Professional, Developer, SysOps Administrator; 2025: AWS Certified AI Practitioner). Konkrete Projekterfahrung umfasst Cloud-Migrationen und Infrastruktur-Aufbau (2019: Migration Oracle Service Bus von OnPremise nach AWS Cloud; 2021: Konzeption einer SAP BW/4HANA Cloud-Infrastruktur auf AWS). Google Cloud Platform Erfahrung ist nicht vorhanden, jedoch sind die Konzepte und Prinzipien √ºbertragbar.

**Git und GitHub Erfahrung:**
Ich verf√ºge √ºber praktische Erfahrung mit Git und GitHub sowie eine aktuelle Zertifizierung (2025: GitHub Copilot Certification). Projektbeispiele zeigen den Einsatz in verschiedenen Kontexten (2019: GitLab CI/CD; 2020: Open-Source Project Life-Scripting mit GitHub).

**Machine Learning und Large Language Models:**
Aktuelle Projekterfahrung mit generativen KI-Modellen und deren Integration (2025: Aufbau einer privaten KI-Wissensumgebung basierend auf LibreChat mit AWS Bedrock, Ollama; 2025: Sichere KI-Chat-L√∂sungen mit RAG-Integration). Die AWS AI Practitioner Zertifizierung deckt SageMaker, Bedrock und weitere ML-Services ab.

**Supply Chain oder operative Daten:**
Langj√§hrige Erfahrung mit Logistik- und Supply Chain-Kunden (2013-2015: Internationaler Transport- und Logistikkonzern; 2017-2019: Internationaler Logistikkonzern; 2021-2024: Deutsches Logistik- und Postunternehmen). Zus√§tzlich SAP BW/4HANA Expertise f√ºr Analytics (2021: Konzeption einer SAP BW/4HANA Cloud-Infrastruktur).

**Datenvisualisierungstools:**
AWS QuickSight ist durch Zertifizierungen abgedeckt, jedoch fehlt praktische Erfahrung mit Tableau, Power BI oder Looker. Diese L√ºcke kann durch die vorhandenen Kenntnisse in Prometheus/Grafana und die schnelle Einarbeitung in neue Tools geschlossen werden.

**SQL und Python sowie Datenpipelines:**
Umfassende Erfahrung mit SQL durch Oracle-Datenbankprojekte und Python-Scripting (2021-2024: Oracle Forms und Reports Migration; 2019: Migration mit Python und bash). Automatisierte Pipeline-Entwicklung durch Infrastructure-as-Code mit Terraform und CI/CD-Erfahrung.

**Gesch√§ftsanforderungen interpretieren und umsetzen:**
Langj√§hrige Beratungserfahrung als Architekt und Berater mit direktem Kundenkontakt und Anforderungsanalyse (seit 2005 selbstst√§ndig; 1998-2005: Business Consultant Principal bei BEA Systems).

**Projektmanagement und Multitasking:**
Erfahrung als technisher Teil-Projektleiter und in der Koordination mehrerer Projekte gleichzeitig (2002-2003: NOA Gro√üprojekte als Teamleiter; kontinuierliche Beratungsprojekte seit 2005).

**Kommunikationsf√§higkeiten und Stakeholder-Management:**
Ausgepr√§gte Kommunikationsf√§higkeiten durch jahrzehntelange Beratert√§tigkeit, Schulungen und Workshops. Zus√§tzlich Ausbildung zum Trainer f√ºr "Cultivating Emotional Balance" zur F√∂rderung achtsamer Arbeitsweise (2017).

**Englischkenntnisse:**
Flie√üende Englischkenntnisse in Wort und Schrift sind vorhanden.

Meine St√§rken liegen in der systematischen Herangehensweise an komplexe IT-Herausforderungen, der F√§higkeit zur schnellen Einarbeitung in neue Technologien und der Verbindung von technischer Expertise mit Gesch√§ftsverst√§ndnis. Die Kombination aus Cloud-Architektur, KI-Integration und Supply Chain-Dom√§nenwissen macht mich zu einem geeigneten Kandidaten f√ºr diese Position.

Eignung f√ºr das Projekt: 85% - Die Kernkompetenzen in AWS, Python, SQL, ML/LLM und Supply Chain-Erfahrung sind stark ausgepr√§gt. L√ºcken bestehen bei GCP-spezifischen Tools und klassischen BI-Visualisierungstools, die jedoch durch die vorhandene Cloud-Expertise und Lernf√§higkeit schnell geschlossen werden k√∂nnen.

Verf√ºgbarkeit: sofort, vollzeit, 80% remote m√∂glich
Gehaltsvorstellung: 110,- ‚Ç¨ pro Stunde

Mit freundlichen Gr√º√üen
Andreas Wittmann
MARKER_APPLICATION_END


---
*Application generated automatically by Bewerbungs-Bot*