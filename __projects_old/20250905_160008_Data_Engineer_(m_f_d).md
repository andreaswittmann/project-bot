---
company: Hays AG
reference_id: '2916329'
scraped_date: '2025-09-05T16:00:08.660072'
source_url: https://www.freelancermap.de/projekt/data-engineer-m-f-d-2916329?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 50% fit score'
  state: rejected
  timestamp: '2025-09-05T16:00:48.126888'
title: Data Engineer (m/f/d)
---


# Data Engineer (m/f/d)
**URL:** [https://www.freelancermap.de/projekt/data-engineer-m-f-d-2916329?ref=rss](https://www.freelancermap.de/projekt/data-engineer-m-f-d-2916329?ref=rss)
## Details
- **Start:** ab sofort
- **Von:** Hays AG
- **Eingestellt:** 05.09.2025
- **Ansprechpartner:** Hays AG
- **Projekt-ID:** 2916329
- **Branche:** IT
- **Vertragsart:** Freiberuflich

## Schlagworte
Microsoft Azure, Data Architecture, Databricks, Datenmanagement, Innovation, Agile Methodologie, Data Analysis, Datenbanken, Information Engineering, Datenmodell, Data Warehousing, Relationale Datenbanken, Ingenieurwesen, Software Architecture

## Beschreibung
**Data Engineer (m/f/d)**

Reference: -en
Start: asap
Duration: 5 MM++

**Main tasks:**

- Data Architecture Development: Design and construct a scalable, efficient, and secure data architecture for a Price Data Product using Azure and Databricks to facilitate advanced data management and analytics
- Data Pipeline Engineering: Develop and maintain reliable data pipelines to enable data harmonization, optimization, and reusability, supporting cross-organizational efficiency and innovation within the Price Data Product
- Team Collaboration and Agile Implementation: Collaborate within a skilled data team to incorporate modern data technologies and methodologies. Drive the integration of agile practices into the development and deployment of data solutions for swift and high-quality outcomes
- Expertise Sharing and Support: Provide expert knowledge on data architecture and engineering, guide organizational data strategies, and promote a culture of data-driven decision-making and continuous learning
- The Data Engineer role is pivotal in establishing and maintaining a state-of-the-art data infrastructure that supports RWE Renewables‚Äô mission to pioneer the energy revolution. This role contributes directly to enhancing our Asset Information data structures and will be responsible to build the Price Data Product that will connect our Assets with the right Prices across the entire Fleet

**Main qualifications:**

- Competencies Required (technical skills, knowledge)
- Azure and Databricks Proficiency: Hands-on experience in using the Azure tool stack and Databricks for data processing and analytics
- Data Management Best Practices: Deep knowledge in data harmonization, storage, distribution, quality, integration, and security principles
- Data Engineering Experience: Proven track record in architecting, developing, and managing data solutions with emphasis on robust data pipeline creation
- Analytical and Problem-Solving Skills: Strong ability to analyze complex issues and proactive problem-solving with a data-driven approach
- Data Technologies Knowledge: Familiarity with database technologies, data warehousing, and data modeling, along with practical experience in relational databases and data analysis
- Optional: Expierienced in working in an Energy related environment

**Main advantages:**

- Support throughout the entire application process

**About us:**
IT is and always has been our core business that laid the foundation for Hays' success. We are the biggest privately owned IT recruitment agency in Germany and offer the best jobs for every career level ‚Äì whether you are interested in vacancies in agile SMEs or international DAX groups. Hays masters the entire IT job spectrum, from support to software architecture or digitalisation ‚Äì thanks to our broad portfolio, we have something for everyone. In the last decades, we were able to support numerous IT experts with choosing the right path for a successful career, positioning ourselves as their lifelong partner. Our highly specialised consultants can cater to your every wish and expectation and will prepare you for interviews and contract negotiations. Give it a try and learn what the market has to offer ‚Äì our services are free of charge, non-binding and discreet! We look forward to hearing from you.

**My contact at Hays:**

My contact person:
Angela Corvitto

Referencenumber:

Make contact:
Email:

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-05T16:00:48.124788

### Pre-Evaluation Phase
- **Score:** 16/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 16%. Found tags: ['ai', 'ki', 'architect', 'architecture', 'pipeline', 'git', 'rest', 'database', 'integration', 'security', 'agile', 'continuous', 'deployment', 'consultant', 'data', 'analytics', 'freelance', 'projekt', 'ant']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 50/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements from project offer:
  - Hands-on Azure tool stack and Databricks
  - Design scalable data architecture and Price Data Product
  - Build/maintain robust data pipelines (harmonization, optimization, reusability)
  - Data management best practices (quality, integration, security)
  - Data warehousing, data modeling, relational DB experience
  - Agile teamwork and knowledge sharing; energy domain a plus

- Strong matches in the CV:
  - Deep cloud architecture experience (many AWS certifications including Solutions Architect Professional) and multi-account/landing-zone design
  - Proven architecture and integration experience across complex enterprise landscapes
  - Hands-on automation/DevOps: Terraform, Docker, CI/CD (GitLab/Jenkins), Infrastructure as Code, Kubernetes (KCNA)
  - Scripting and tooling: Python, bash, Git; experience creating automated pipelines for migrations and deployments
  - Relational DB experience (Oracle, RDS) and experience designing a SAP BW/4HANA on AWS (data-warehouse related architecture)
  - Agile methods, team coaching and documentation practices (Live-Scripting, workshops, pair programming)

- Gaps / risks versus the job:
  - No explicit Azure experience listed (offer requires Azure tool stack)
  - No Databricks experience shown (core requirement)
  - Limited explicit evidence of large-scale data engineering on big-data stacks (Spark/Delta Lake data modeling, ETL tooling specific to Databricks)
  - Data-product/price-data domain experience not shown; energy-sector experience not present

- Assessment / recommendation:
  - Candidate is a strong cloud architect/DevOps engineer with solid automation, Python and database skills and relevant data-warehouse architecture exposure (SAP BW on AWS). However, the two primary technical gaps (Azure + Databricks) are significant for a hands-on Data Engineer role focused on Databricks on Azure. If the client is flexible (willing to accept an AWS-native architect who can learn Azure/Databricks quickly) this candidate could ramp up fast given strong architecture and automation background. If the role requires immediate, proven Databricks + Azure hands‚Äëon experience, this is a medium/low fit.

- Score rationale: 50/100 ‚Äî strong on cloud architecture, infra-as-code, pipelines and relational DBs; weak on the required Azure + Databricks stack and explicit big-data engineering experience.

---
