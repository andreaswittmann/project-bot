---
company: Allegis Group GmbH - Bereich Actalent Services
reference_id: '2916201'
scraped_date: '2025-09-05T14:00:08.398729'
source_url: https://www.freelancermap.de/projekt/teilzeit-mit-20-25h-pro-woche-data-engineer-python-developer-m-f-d?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 53% fit score'
  state: rejected
  timestamp: '2025-09-05T14:01:18.289469'
title: Teilzeit mit 20-25h pro Woche, Data Engineer / Python Developer (m/f/d)
---


# Teilzeit mit 20-25h pro Woche, Data Engineer / Python Developer (m/f/d)
**URL:** [https://www.freelancermap.de/projekt/teilzeit-mit-20-25h-pro-woche-data-engineer-python-developer-m-f-d?ref=rss](https://www.freelancermap.de/projekt/teilzeit-mit-20-25h-pro-woche-data-engineer-python-developer-m-f-d?ref=rss)
## Details
- **Start:** ab sofort
- **Von:** Allegis Group GmbH - Bereich Actalent Services
- **Auslastung:** 60% (3 Tage pro Woche)
- **Eingestellt:** 05.09.2025
- **Ansprechpartner:** Didem Oezer
- **Projekt-ID:** 2916201
- **Branche:** IT
- **Vertragsart:** Freiberuflich
- **Einsatzart:** 100
                                                % Remote

## Schlagworte
Python, Airflow, Datenmodell, Apache Hbase, Gitlab, Software Quality, Code-Review, √ñffentlichkeitsarbeit, Dags, Infrastruktur, √úbersetzungen, Node.Js, Workflows, Datenverarbeitung, Git, Technisches Geschick, Software Version Control, Technische Beratung

## Beschreibung
Freiberuflicher Data Engineer / Python Developer (m/w/d)

Teilzeit: 20‚Äì25 Stunden pro Woche

Wir suchen derzeit einen erfahrenen Data Engineer / Python Developer als externer Beraterin f√ºr ein strategisches Projekt. Diese Rolle eignet sich ideal f√ºr Fachkr√§fte mit fundierten technischen Kenntnissen in der Datenverarbeitung und Python-Entwicklung, insbesondere im Umfeld verteilter Infrastrukturplattformen.

Projekt√ºbersicht

Sie unterst√ºtzen die Konzeption und Implementierung eines zentralisierten DataHub auf einer Multi-Node-Infrastrukturplattform. Der DataHub integriert Daten aus verschiedenen Quellen in ein einheitliches Modell und stellt diese produktiv f√ºr externe Systeme bereit.

Start: schnellstm√∂glich
Ort: vollst√§ndig remote
Auslastung: Teilzeit mit 20 bis 25 Stunden pro Woche

Technologien

Apache Airflow ‚Äì zur Orchestrierung von Datenpipelines (DAGs)
HBase ‚Äì als Persistenzschicht f√ºr strukturierte Daten
HPE Ezmeral Data Fabric ‚Äì als zugrunde liegende Infrastruktur
GitLab ‚Äì f√ºr Versionskontrolle und Dokumentatio

Aufgaben

Entwurf und Konzeption skalierbarer Datenmodelle
Integration neuer Datenquellen und -senken in den DataHub
√úbersetzung architektonischer Konzepte in umsetzbare Entwicklungstickets
Durchf√ºhrung von Code-Reviews zur Sicherstellung von Qualit√§t und Wartbarkeit
Test und Validierung von Airflow-Pipelines
Technische Beratung zu HBase und Data Fabric
Enge Zusammenarbeit mit funktions√ºbergreifenden Teams

Erforderliche Kenntnisse & Qualifikationen

Verhandlungssicheres Deutsch in Wort und Schrift
Fortgeschrittene Kenntnisse in Python
Tiefes Verst√§ndnis von Datenmodellierung und Schema-Entwicklung
Vertrautheit mit spaltenbasierten Datenspeichern
Erfahrung mit Git/GitLab, Codequalit√§t und PR-Workflows
Ausgepr√§gte F√§higkeiten zur Probleml√∂sung und Abstraktion
Sicheres Arbeiten in agilen Teams

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-05T14:01:18.286251

### Pre-Evaluation Phase
- **Score:** 13/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 13%. Found tags: ['ai', 'ml', 'architekt', 'pipeline', 'gitlab', 'python', 'git', 'integration', 'agile', 'berater', 'beratung', 'data', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 53/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements (from project):
  - Fortgeschrittene Python-Kenntnisse
  - Apache Airflow (Entwicklung, Test, DAGs)
  - HBase (spaltenbasierte Persistenz)
  - HPE Ezmeral Data Fabric (Multi-node Data-Fabric)
  - Git/GitLab (CI/CD, PR-Workflows, Code-Reviews)
  - Datenmodellierung / Schema-Design (skalierbare Modelle)
  - Erfahrung mit spaltenbasierten/analytischen Datenspeichern
  - Code-Reviews, Qualit√§tssicherung, agile Zusammenarbeit
  - Verhandlungssicheres Deutsch; remote/freelance-Eignung

- Abgleich mit dem CV (St√§rken):
  - Python: mehrfach eingesetzte Technik in vielen Projekten ‚Üí starke √úbereinstimmung.
  - Git/GitLab: Erfahrung mit Git, GitLab CI/CD und GitHub (inkl. Copilot) ‚Üí passt gut.
  - Datenmodellierung / DB-Expertise: umfangreiche DB- und Architekturarbeit (Oracle, SAP BW/4HANA, Migrationen) ‚Üí guter Fit f√ºr konzeptionelle Modellierungsaufgaben.
  - Infrastruktur & verteilte Systeme: umfangreiche AWS-, Kubernetes-, Terraform- und DevOps-Erfahrung ‚Üí sehr geeignet f√ºr Multi-node-Umgebungen allgemein.
  - Code-Reviews, Architektur- und Design-Reviews: explizit angegeben ‚Üí erf√ºllt.
  - Deutsch: Muttersprache ‚Üí erf√ºllt; Freelance-/Remote-Erfahrung vorhanden.

- Abgleich mit dem CV (L√ºcken / Risiken):
  - Apache Airflow: im CV keine explizite Nennung von Airflow oder DAG-Entwicklung/-Tests ‚Üí relevantes Defizit f√ºr diese Rolle.
  - HBase und HPE Ezmeral Data Fabric: keine Erw√§hnung praktischer Erfahrung mit HBase oder Ezmeral ‚Üí signifikanter technischer Gap f√ºr die Persistenz- und Plattformanforderung.
  - Spaltenbasierte/Big-Data-Stores: indirekte/partielle √úberschneidung (z. B. AWS-Services wie Redshift in Skills-Liste, Elastic/OpenSearch Erfahrungen), aber kein klares HBase/NoSQL-Produktwissen.
  - Explizite Node.js- oder spezifische DataHub-Erfahrung: nicht vorhanden oder nicht klar dokumentiert.

- Einsch√§tzung / Empfehlung:
  - Der Kandidat bringt starke Cloud-, Infrastruktur-, DevOps- und Python-/Architekturkompetenz mit ‚Äî gute Basis f√ºr den Data-Engineering-Kontext.
  - Die fehlende, explizite Erfahrung mit Apache Airflow und HBase / Ezmeral ist f√ºr die Kerntechnologien dieses Projekts jedoch kritisch. Wenn der Kunde strikt Hands-on-Expertise in Airflow + HBase/Ezmeral erwartet, ist der Kandidat nur eingeschr√§nkt passend.
  - Falls die Rolle Raum f√ºr Einarbeitung bietet (z. B. Airflow/HBase on-the-job lernen) oder Schwerpunkt mehr auf Datenmodellierung, Python-Integration und Cloud-Infrastruktur liegt, ist der Kandidat eine solide Wahl.

- Kurze Begr√ºndung der Punktzahl (53/100):
  - Volle Punkte f√ºr Python, Datenmodellierung, Git/GitLab, Cloud/DevOps, Deutsch und Code-Review-Fertigkeiten;
  - Starke Abz√ºge wegen fehlender nachgewiesener Airflow- und HBase/Ezmeral-Erfahrung, die zentrale Anforderungen der Stelle sind.

---
