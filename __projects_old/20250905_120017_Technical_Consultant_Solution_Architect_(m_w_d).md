---
company: SOLCOM GmbH
reference_id: '2916136'
scraped_date: '2025-09-05T12:00:17.679668'
source_url: https://www.freelancermap.de/projekt/technical-consultant-solution-architect-m-w-d?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 50% fit score'
  state: rejected
  timestamp: '2025-09-05T12:03:10.862914'
title: Technical Consultant/ Solution Architect (m/w/d)
---


# Technical Consultant/ Solution Architect (m/w/d)
**URL:** [https://www.freelancermap.de/projekt/technical-consultant-solution-architect-m-w-d?ref=rss](https://www.freelancermap.de/projekt/technical-consultant-solution-architect-m-w-d?ref=rss)
## Details
- **Start:** ab sofort
- **Von:** SOLCOM GmbH
- **Eingestellt:** 05.09.2025
- **Ansprechpartner:** SOLCOM GmbH
- **Projekt-ID:** 2916136
- **Branche:** IT
- **Vertragsart:** Freiberuflich
- **Einsatzart:** 100
                                                % Remote

## Schlagworte
Software Quality, Datenmodell, Innovation, Agile Methodologie, Airflow, Code-Review, √ñffentlichkeitsarbeit, Ingenieurwesen, Apache Hbase, Python, Node.Js, Scrum, Softwareentwicklung, Workflows, Ablaufplanung, Testen, Gitlab, Git, Technische Beratung

## Beschreibung
**Aufgaben:**

Aktuell sind wir f√ºr einen unserer Kunden auf der Suche nach einem Technical Consultant/ Solution Architect f√ºr die Konzeption und Implementierung eines zentralisierten DataHubs auf einer Multi-Node-Infrastrukturplattform.

Einsatzort: Remote

Auslastung: 20-25 Stunden/Woche

Zu Ihren Aufgaben geh√∂ren:

+ Planung und Konzeption von Datenmodellen sowie der Integration neuer Datenquellen und -senken

+ Erstellung von Tickets f√ºr Entwickler auf Basis architektonischer Konzepte

+ Durchf√ºhrung von Code-Reviews zur Sicherstellung von Nutzbarkeit und Codequalit√§t

+ Testen von Airflow-Implementierungen zur √úberpr√ºfung der Funktionalit√§t und erwarteten Ergebnisse

+ Technische Beratung zur Nutzung von Data Fabric und Hbase

Projekt-Nr.:
101739

Projekttitel:
Technical Consultant/ Solution Architect (m/w/d)

Stellentyp:
freiberuflich

Einsatzort:
Remote

Starttermin:
asap

Dauer:
ungewiss

**Anforderungen:**

+ Erfahrung mit HPE Ezmeral Data Fabric

+ Verhandlungssichere Deutschkenntnisse in Wort und Schrift

+ Fortgeschrittene Kenntnisse in Python

+ Fundiertes Wissen √ºber Datenmodelle und deren Erweiterung/Anpassung

+ Grundverst√§ndnis von spaltenbasierten Daten

+ Erfahrung mit Git/GitLab, Codequalit√§t und PR-Workflows

+ Vertrautheit mit agilen Methoden (Scrum)

**Zus√§tzliche Informationen:**
Konnten wir Ihr Interesse wecken? Dann freuen wir uns auf die Zusendung Ihres aussagekr√§ftigen Expertenprofils unter Angabe Ihrer Stundensatzvorstellung.

SOLCOM z√§hlt zu den f√ºhrenden Technologiedienstleistern in den Bereichen Softwareentwicklung, IT und Engineering. Seit mehr als 20 Jahren arbeiten wir als Partner global agierender Spitzenunternehmen aller Branchen und sind weltweit im Einsatz, wo Innovation entscheidet.

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-05T12:03:10.859154

### Pre-Evaluation Phase
- **Score:** 15/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 15%. Found tags: ['ai', 'architect', 'architekt', 'solution architect', 'gitlab', 'python', 'git', 'integration', 'agile', 'scrum', 'consultant', 'beratung', 'data', 'remote', 'freelance', 'projekt', 'ant']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 50/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements (summary):
  - HPE Ezmeral Data Fabric experience (explicit)
  - Apache HBase / columnar / big-data store familiarity
  - Fortgeschrittene Python-Kenntnisse
  - Erfahrung mit Airflow (Test/Validierung von DAGs / Workflows)
  - Datenmodellierung und Erweiterung/Anpassung von Datenmodellen
  - Git/GitLab, Code-Reviews und PR-Workflows
  - Vertrautheit mit agilen Methoden (Scrum)
  - Verhandlungssicheres Deutsch, remote-f√§hig, Teilzeit (20‚Äì25 h/Woche)

- Match / evidence from CV:
  - + Python: mehrfach eingesetzte Sprache in Projekten (Automation, Scripting, Boto3). (stark)
  - + Git/GitLab & CI/CD: Erfahrung mit Git, GitLab CI/CD, Jenkins; Live-scripting and automation practices. (stark)
  - + Code-Reviews / Architektur & Ticket-Erstellung: langj√§hrige Erfahrung als Architekt/Berater, Mentoring, Reviews und Erstellen technischer Konzepte. (stark)
  - + Datenmodell/Big-Workloads: Erfahrung mit SAP BW/4HANA-Architektur, Redshift listed among AWS services; understands large-scale data architectures. (good partial match)
  - + Agile: Scrum/Kanban Erfahrung wird mehrfach genannt. (match)
  - + Deutsch: Muttersprache Deutsch (voll erf√ºllt)
  - + Multi-node / infra / cloud: umfangreiche cloud-, Kubernetes-, Terraform- und AWS-Architektur-Erfahrung (match for multi-node infra)

- Gaps / risks:
  - - HPE Ezmeral Data Fabric: no explicit experience listed. This is a specific platform requirement. (missing)
  - - Apache HBase: not mentioned anywhere in CV; HBase is a specific technology (missing)
  - - Apache Airflow: no explicit Airflow experience or DAG testing described. (missing)
  - - While many AWS data services are known, hands-on experience with the target stack (Ezmeral + HBase + Airflow) is not demonstrated‚Äîcould require ramp-up.

- Overall assessment and recommendation:
  - Andreas is a strong cloud/architect/DevOps consultant with solid Python, GitLab CI/CD, code-review and data-architecture skills and native German. He would likely be effective for architecture, modelling, ticketing, reviews and infra guidance.
  - However, the project explicitly asks for HPE Ezmeral Data Fabric, HBase and Airflow testing experience‚Äîspecialized items missing from the CV. If the client can accept fast ramp-up on those technologies (given his strong adjacent skills), he is a good candidate. If the client requires immediate, hands-on Ezmeral/HBase/Airflow specialists, this candidate is a partial but not ideal fit.

- Fit rationale score: 50/100 ‚Äî strong on architecture, Python, GitLab, agile and cloud infra; notable misses on the platform-specific HPE Ezmeral, HBase and Airflow requirements.

---
