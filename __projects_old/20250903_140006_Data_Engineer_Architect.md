---
company: Source Technology Ltd.
reference_id: '2915334'
scraped_date: '2025-09-03T14:00:06.805611'
source_url: https://www.freelancermap.de/projekt/data-engineer-architect-2915334?ref=rss
state: rejected
state_history:
- note: 'LLM evaluation: 75% fit score'
  state: rejected
  timestamp: '2025-09-03T14:03:09.536857'
title: Data Engineer/Architect
---


# Data Engineer/Architect
**URL:** [https://www.freelancermap.de/projekt/data-engineer-architect-2915334?ref=rss](https://www.freelancermap.de/projekt/data-engineer-architect-2915334?ref=rss)
## Details
- **Start:** ab sofort
- **Von:** Source Technology Ltd.
- **Auslastung:** 100% (5 Tage pro Woche)
- **Eingestellt:** 03.09.2025
- **Ansprechpartner:** Olly Black
- **Projekt-ID:** 2915334
- **Branche:** Medien- und Entertainment
- **Vertragsart:** Freiberuflich

## Schlagworte
Data Architecture, Data Lake, Amazon Web Services, Data Warehousing, Steuerung, Information Engineering, Data Governance, ETL, Datenmodell, SQL, Streaming, System Design, Cloud Platform

## Beschreibung
A large customer of mine are currently looking for an experienced Data Architect to design, optimize, and manage our enterprise data ecosystem. You‚Äôll define data strategies, ensure scalability, and enable advanced analytics that drive smarter business decisions.

This role is remote, and can be done anywhere within 1hr of CET timezone. EU based candidates only.

Rates dependent on experience.

For any enquiries, please reach out directly to

Your role will be to design and develop a Datalake/Datamesh in AWS with data cataloguing and governance
- Design and implement enterprise data architecture (data models, pipelines, warehouses, lakes)
- Define data governance, quality, and security principles
- Evaluate and implement modern data technologies (Datawarehouse/Datalake/Lakehouse)
- Optimize data storage and integration for performance and cost efficiency.

Must haves (experience in years, Tools, sectors):
- 3-5 years of experience in data engineering
- 2-3 years of experience as a data architect or similar with system design experience
- Experience with design data stream pipelines
- Strong knowledge of SQL, data modeling, cloud platforms (AWS)
- Experience with ETL/ELT frameworks, data lakes, data warehouses and data streaming architectures.
- Familiarity with governance, compliance and security frameworks.
- Excellent communication and problem-solving skills

---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T14:03:09.533103

### Pre-Evaluation Phase
- **Score:** 21/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 21%. Found tags: ['aws', 'amazon', 'ai', 'ki', 'cloud', 'architect', 'architecture', 'pipeline', 'sql', 'enterprise', 'integration', 'security', 'compliance', 'data', 'analytics', 'etl', 'streaming', 'scalability', 'performance', 'remote', 'freelance', 'projekt']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 75/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements from the brief: AWS (data services), design/implement Data Lake / Lakehouse / Data Mesh, data modelling, SQL, ETL/ELT frameworks, streaming pipelines, data cataloguing & governance, 3‚Äì5 years data-engineering + 2‚Äì3 years data-architecture/system-design, EU/CET remote.
- Strong matches (evidence in CV): extensive AWS expertise and up-to-date certifications (Solutions Architect Professional, many AWS services listed including Glue, Lake Formation, Athena, Kinesis, MSK, Redshift, S3, DMS, EMR, QuickSight); demonstrated cloud architecture work (Landing Zone, multi-account designs, SAP BW/4HANA on AWS); experience with Terraform, IaC, CI/CD and automation; long history of systems architecture, security & governance awareness; strong SQL/Oracle background and migration projects involving data platforms.
- Partial matches: explicit knowledge of data-catalogue/governance tools is mentioned via AWS Lake Formation and other AWS security/Governance services, but hands-on deliverables for enterprise data-catalog implementations are not strongly detailed. Streaming knowledge (Kinesis, MSK) appears in the skills list, but few projects describe end-to-end real-time pipeline builds.
- Gaps / risks: limited explicit hands-on evidence for modern data-engineering stacks (e.g., Spark/Databricks, Airflow, dbt, Delta Lake) and few concrete recent projects framed as 'data engineering' (most recent projects are cloud architecture, AI/LibreChat, middleware migrations); unclear whether 3‚Äì5 years of continuous, hands-on data-engineering work is met vs. architectural/consulting experience around data platforms.
- Logistics & soft skills: location (Hamburg) fits CET requirement; senior consulting background indicates strong communication and stakeholder skills required for architect role.
- Summary recommendation: Very good fit for the Data Architect aspects (AWS architecture, governance, landing zones, data platform design). Candidate may need to demonstrate or be supported on specific modern data-engineering toolchains and hands‚Äëon pipeline implementation experience to fully meet the 'data engineer' hands-on expectation. Hence a conservative strong fit score of 75/100.

---


---

## ü§ñ AI Evaluation Results

**Evaluation Timestamp:** 2025-09-03T14:05:00.497666

### Pre-Evaluation Phase
- **Score:** 33/100
- **Threshold:** 10/100
- **Result:** ‚úÖ Passed
- **Rationale:** Score: 33%. Found tags: ['aws', 'amazon', 'ai', 'ki', 'llm', 'openai', 'cloud', 'terraform', 'architect', 'cloud architect', 'architecture', 'ci/cd', 'pipeline', 'automation', 'iac', 'oracle', 'sql', 'enterprise', 'middleware', 'integration', 'security', 'compliance', 'continuous', 'consulting', 'data', 'analytics', 'etl', 'streaming', 'scalability', 'performance', 'remote', 'freelance', 'projekt', 'project']

### LLM Analysis Phase
- **LLM Provider:** OpenAI
- **LLM Model:** gpt-5-mini
- **Fit Score:** 78/100
- **Acceptance Threshold:** 85/100
- **Final Decision:** ‚ùå REJECTED

#### Detailed Rationale
- Key requirements:
  - Design and implement Data Lake / Data Mesh / Lakehouse on AWS, with data cataloguing and governance
  - Data modelling, SQL, ETL/ELT frameworks, data warehouses/lakes, streaming pipelines
  - 3‚Äì5 years data-engineering hands‚Äëon + 2‚Äì3 years data‚Äëarchitecture/system‚Äëdesign
  - Familiarity with governance, compliance and security; cost/performance optimisation
  - Excellent communication; EU/CET remote

- Strong matches:
  - Deep AWS expertise and up‚Äëto‚Äëdate certifications (Solutions Architect Pro + many AWS services listed including Glue, Lake Formation, Athena, Kinesis, MSK, Redshift, EMR, DMS, S3)
  - Proven enterprise architecture experience (Landing Zones, multi‚Äëaccount designs, SAP BW/4HANA on AWS, cost/monitoring and security design)
  - Long history of systems architecture, migrations and platform design ‚Äî strong on governance, security and operational best practices
  - Solid SQL and database experience (Oracle migrations, data migrations) and automation/IaC (Terraform, CI/CD)
  - Location and senior consulting/communication skills align with role requirements

- Partial matches:
  - Data catalogue/governance tooling is present in the skill list (Lake Formation, IAM, Config, Security Hub), but few projects describe end‚Äëto‚Äëend catalogue implementations
  - Streaming services (Kinesis, MSK) appear in skills, but there is limited explicit evidence of recent, large‚Äëscale streaming pipeline builds

- Gaps / risks:
  - Limited explicit hands‚Äëon evidence for modern data‚Äëengineer toolchain (e.g., Spark/Databricks, Apache Airflow, dbt, Delta Lake) in project descriptions
  - Many recent engagements are architecture/consulting and middleware migrations rather than labeled data‚Äëengineering pipeline development ‚Äî may need to demonstrate hands‚Äëon pipeline coding/operational experience

- Conclusion / recommendation:
  - Very strong fit on the Data Architect side (AWS, governance, enterprise data platform design). Candidate likely meets architecture and leadership needs; to cover pure hands‚Äëon data‚Äëengineer expectations, request concrete examples of recent ETL/ELT pipeline builds, orchestration tools (Airflow/Glue workflows), Spark/EMR/Databricks usage or propose a short technical assignment/proof‚Äëof‚Äëconcept focusing on streaming and pipeline implementation.

---
